{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Streaming Wars: Song Popularity Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: E. Berke Tezcan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/apple-music-spotify-tidal.jpg\" style=\"width: 60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T00:03:15.139565Z",
     "start_time": "2021-05-24T00:03:15.130551Z"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TABLE OF CONTENTS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click to jump to matching Markdown Header.*<br><br>\n",
    " \n",
    "- **[Introduction](#INTRODUCTION)<br>**\n",
    "- **[OBTAIN](#OBTAIN)**<br>\n",
    "- **[SCRUB/EXPLORE](#SCRUB/EXPLORE)**<br>\n",
    "- **[MODEL](#MODEL)**<br>\n",
    "- **[iNTERPRET](#iNTERPRET)**<br>\n",
    "- **[Conclusions/Recommendations](#CONCLUSIONS-&-RECOMMENDATIONS)<br>**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Apple Music announcing on May 17th that they will be providing lossless audio along with spatial audio by Dolby Atmos for their subscribers and Tidal continuously providing exclusive content from artists, the competition among audio streaming platforms is heating up. Spotify would like to stay competitive by being able to predict which songs are going to be popular ahead of time so that they can curate even better playlists and sign deals with up-and-coming artists to have exclusivity on their content. This would not only help retain the current subscribers but also help market the platform to new subscribers as well.\n",
    "\n",
    "For this project, we were hired by Spotify to develop a machine learning model that can accurately predict whether a song is going to be popular or not. In order to achieve this, we will be evaluating different machine learning models and will look at what attributes of a song are the most important for determining its popularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a dataset from Kaggle (https://www.kaggle.com/zaheenhamidani/ultimate-spotify-tracks-db) that contains approximately 232,000 tracks and their attributes to train several machine learning models in order to find the common threads between popular songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:46:51.210776Z",
     "start_time": "2021-05-27T15:46:50.647103Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:46:51.947366Z",
     "start_time": "2021-05-27T15:46:51.212775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Movie</td>\n",
       "      <td>Henri Salvador</td>\n",
       "      <td>C'est beau de faire un Show</td>\n",
       "      <td>0BRjO6ga9RKCKjfDqeFgWV</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.389</td>\n",
       "      <td>99373</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.000</td>\n",
       "      <td>C#</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>-1.828</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>166.969</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie</td>\n",
       "      <td>Martin &amp; les fées</td>\n",
       "      <td>Perdu d'avance (par Gad Elmaleh)</td>\n",
       "      <td>0BjC1NfoEOOusryehmNudP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.590</td>\n",
       "      <td>137373</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.000</td>\n",
       "      <td>F#</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-5.559</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>174.003</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Movie</td>\n",
       "      <td>Joseph Williams</td>\n",
       "      <td>Don't Let Me Be Lonely Tonight</td>\n",
       "      <td>0CoSDzoNIKCRs124s9uTVy</td>\n",
       "      <td>3</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.663</td>\n",
       "      <td>170267</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.000</td>\n",
       "      <td>C</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>-13.879</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>99.488</td>\n",
       "      <td>5/4</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Movie</td>\n",
       "      <td>Henri Salvador</td>\n",
       "      <td>Dis-moi Monsieur Gordon Cooper</td>\n",
       "      <td>0Gc6TVm52BwZD07Ki6tIvf</td>\n",
       "      <td>0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.240</td>\n",
       "      <td>152427</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>C#</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>-12.178</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>171.758</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Movie</td>\n",
       "      <td>Fabien Nataf</td>\n",
       "      <td>Ouverture</td>\n",
       "      <td>0IuslXpMROHdEPvSl1fTQK</td>\n",
       "      <td>4</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.331</td>\n",
       "      <td>82625</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.123</td>\n",
       "      <td>F</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>-21.150</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>140.576</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genre        artist_name                        track_name  \\\n",
       "0  Movie     Henri Salvador       C'est beau de faire un Show   \n",
       "1  Movie  Martin & les fées  Perdu d'avance (par Gad Elmaleh)   \n",
       "2  Movie    Joseph Williams    Don't Let Me Be Lonely Tonight   \n",
       "3  Movie     Henri Salvador    Dis-moi Monsieur Gordon Cooper   \n",
       "4  Movie       Fabien Nataf                         Ouverture   \n",
       "\n",
       "                 track_id  popularity  acousticness  danceability  \\\n",
       "0  0BRjO6ga9RKCKjfDqeFgWV           0         0.611         0.389   \n",
       "1  0BjC1NfoEOOusryehmNudP           1         0.246         0.590   \n",
       "2  0CoSDzoNIKCRs124s9uTVy           3         0.952         0.663   \n",
       "3  0Gc6TVm52BwZD07Ki6tIvf           0         0.703         0.240   \n",
       "4  0IuslXpMROHdEPvSl1fTQK           4         0.950         0.331   \n",
       "\n",
       "   duration_ms  energy  instrumentalness key  liveness  loudness   mode  \\\n",
       "0        99373   0.910             0.000  C#    0.3460    -1.828  Major   \n",
       "1       137373   0.737             0.000  F#    0.1510    -5.559  Minor   \n",
       "2       170267   0.131             0.000   C    0.1030   -13.879  Minor   \n",
       "3       152427   0.326             0.000  C#    0.0985   -12.178  Major   \n",
       "4        82625   0.225             0.123   F    0.2020   -21.150  Major   \n",
       "\n",
       "   speechiness    tempo time_signature  valence  \n",
       "0       0.0525  166.969            4/4    0.814  \n",
       "1       0.0868  174.003            4/4    0.816  \n",
       "2       0.0362   99.488            5/4    0.368  \n",
       "3       0.0395  171.758            4/4    0.227  \n",
       "4       0.0456  140.576            4/4    0.390  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing data into a dataframe\n",
    "df = pd.read_csv('./data/SpotifyFeatures.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:46:52.151233Z",
     "start_time": "2021-05-27T15:46:51.949350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>232725.000000</td>\n",
       "      <td>232725.000000</td>\n",
       "      <td>232725.000000</td>\n",
       "      <td>2.327250e+05</td>\n",
       "      <td>232725.000000</td>\n",
       "      <td>232725.000000</td>\n",
       "      <td>232725.000000</td>\n",
       "      <td>232725.000000</td>\n",
       "      <td>232725.000000</td>\n",
       "      <td>232725.000000</td>\n",
       "      <td>232725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.127502</td>\n",
       "      <td>0.368560</td>\n",
       "      <td>0.554364</td>\n",
       "      <td>2.351223e+05</td>\n",
       "      <td>0.570958</td>\n",
       "      <td>0.148301</td>\n",
       "      <td>0.215009</td>\n",
       "      <td>-9.569885</td>\n",
       "      <td>0.120765</td>\n",
       "      <td>117.666585</td>\n",
       "      <td>0.454917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.189948</td>\n",
       "      <td>0.354768</td>\n",
       "      <td>0.185608</td>\n",
       "      <td>1.189359e+05</td>\n",
       "      <td>0.263456</td>\n",
       "      <td>0.302768</td>\n",
       "      <td>0.198273</td>\n",
       "      <td>5.998204</td>\n",
       "      <td>0.185518</td>\n",
       "      <td>30.898907</td>\n",
       "      <td>0.260065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>1.538700e+04</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009670</td>\n",
       "      <td>-52.457000</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>30.379000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>1.828570e+05</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>-11.771000</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>92.959000</td>\n",
       "      <td>0.237000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>2.204270e+05</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>-7.762000</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>115.778000</td>\n",
       "      <td>0.444000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.722000</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>2.657680e+05</td>\n",
       "      <td>0.787000</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>-5.501000</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>139.054000</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.989000</td>\n",
       "      <td>5.552917e+06</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.744000</td>\n",
       "      <td>0.967000</td>\n",
       "      <td>242.903000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          popularity   acousticness   danceability   duration_ms  \\\n",
       "count  232725.000000  232725.000000  232725.000000  2.327250e+05   \n",
       "mean       41.127502       0.368560       0.554364  2.351223e+05   \n",
       "std        18.189948       0.354768       0.185608  1.189359e+05   \n",
       "min         0.000000       0.000000       0.056900  1.538700e+04   \n",
       "25%        29.000000       0.037600       0.435000  1.828570e+05   \n",
       "50%        43.000000       0.232000       0.571000  2.204270e+05   \n",
       "75%        55.000000       0.722000       0.692000  2.657680e+05   \n",
       "max       100.000000       0.996000       0.989000  5.552917e+06   \n",
       "\n",
       "              energy  instrumentalness       liveness       loudness  \\\n",
       "count  232725.000000     232725.000000  232725.000000  232725.000000   \n",
       "mean        0.570958          0.148301       0.215009      -9.569885   \n",
       "std         0.263456          0.302768       0.198273       5.998204   \n",
       "min         0.000020          0.000000       0.009670     -52.457000   \n",
       "25%         0.385000          0.000000       0.097400     -11.771000   \n",
       "50%         0.605000          0.000044       0.128000      -7.762000   \n",
       "75%         0.787000          0.035800       0.264000      -5.501000   \n",
       "max         0.999000          0.999000       1.000000       3.744000   \n",
       "\n",
       "         speechiness          tempo        valence  \n",
       "count  232725.000000  232725.000000  232725.000000  \n",
       "mean        0.120765     117.666585       0.454917  \n",
       "std         0.185518      30.898907       0.260065  \n",
       "min         0.022200      30.379000       0.000000  \n",
       "25%         0.036700      92.959000       0.237000  \n",
       "50%         0.050100     115.778000       0.444000  \n",
       "75%         0.105000     139.054000       0.660000  \n",
       "max         0.967000     242.903000       1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at the stats of different columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:46:52.245179Z",
     "start_time": "2021-05-27T15:46:52.154232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 232725 entries, 0 to 232724\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   genre             232725 non-null  object \n",
      " 1   artist_name       232725 non-null  object \n",
      " 2   track_name        232725 non-null  object \n",
      " 3   track_id          232725 non-null  object \n",
      " 4   popularity        232725 non-null  int64  \n",
      " 5   acousticness      232725 non-null  float64\n",
      " 6   danceability      232725 non-null  float64\n",
      " 7   duration_ms       232725 non-null  int64  \n",
      " 8   energy            232725 non-null  float64\n",
      " 9   instrumentalness  232725 non-null  float64\n",
      " 10  key               232725 non-null  object \n",
      " 11  liveness          232725 non-null  float64\n",
      " 12  loudness          232725 non-null  float64\n",
      " 13  mode              232725 non-null  object \n",
      " 14  speechiness       232725 non-null  float64\n",
      " 15  tempo             232725 non-null  float64\n",
      " 16  time_signature    232725 non-null  object \n",
      " 17  valence           232725 non-null  float64\n",
      "dtypes: float64(9), int64(2), object(7)\n",
      "memory usage: 32.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We once again see that we have 232,725 tracks in the dataset with both categorical and numerical columns. In order to use the information from the categorical columns ('genre', 'artist_name', 'track_name', 'track_id', 'key', 'mode', 'time_signature') we will either need to represent them numerically by feature engineering or drop them to be able to train the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:46:52.890723Z",
     "start_time": "2021-05-27T15:46:52.247181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: genre\n",
      "Comedy              9681\n",
      "Soundtrack          9646\n",
      "Indie               9543\n",
      "Jazz                9441\n",
      "Pop                 9386\n",
      "Electronic          9377\n",
      "Children’s Music    9353\n",
      "Folk                9299\n",
      "Hip-Hop             9295\n",
      "Rock                9272\n",
      "Alternative         9263\n",
      "Classical           9256\n",
      "Rap                 9232\n",
      "World               9096\n",
      "Soul                9089\n",
      "Blues               9023\n",
      "R&B                 8992\n",
      "Anime               8936\n",
      "Reggaeton           8927\n",
      "Ska                 8874\n",
      "Reggae              8771\n",
      "Dance               8701\n",
      "Country             8664\n",
      "Opera               8280\n",
      "Movie               7806\n",
      "Children's Music    5403\n",
      "A Capella            119\n",
      "Name: genre, dtype: int64\n",
      "--------------------\n",
      "Column: artist_name\n",
      "Giuseppe Verdi               1394\n",
      "Giacomo Puccini              1137\n",
      "Kimbo Children's Music        971\n",
      "Nobuo Uematsu                 825\n",
      "Richard Wagner                804\n",
      "                             ... \n",
      "Grits                           1\n",
      "Marcus Gilmore                  1\n",
      "The Olivia Tremor Control       1\n",
      "George Butterworth              1\n",
      "Dexter Story                    1\n",
      "Name: artist_name, Length: 14564, dtype: int64\n",
      "--------------------\n",
      "Column: track_name\n",
      "Home                    100\n",
      "You                      71\n",
      "Intro                    69\n",
      "Stay                     63\n",
      "Wake Up                  59\n",
      "                       ... \n",
      "House In The Trees        1\n",
      "灼熱の刃 〜 ディノバルド             1\n",
      "Not a Word                1\n",
      "You Got Me Floatin'       1\n",
      "The Impossible Waves      1\n",
      "Name: track_name, Length: 148615, dtype: int64\n",
      "--------------------\n",
      "Column: track_id\n",
      "3R73Y7X53MIQZWnKloWq5i    8\n",
      "0wY9rA9fJkuESyYm9uzVK5    8\n",
      "3uSSjnDMmoyERaAK9KvpJR    8\n",
      "0UE0RhnRaEYsiYgXpyLoZc    8\n",
      "6sVQNUvcVFTXvlk3ec0ngd    8\n",
      "                         ..\n",
      "3A50RFIzgUphr3ea4o6lkx    1\n",
      "3oCesNHKbD8rV5eSeflvrF    1\n",
      "37xiaeRdAfIIse2f1cZ29a    1\n",
      "7dHe2GYzd4qKr494s7Va3e    1\n",
      "0rnnh0OQkZhH5W1FCuF0Cr    1\n",
      "Name: track_id, Length: 176774, dtype: int64\n",
      "--------------------\n",
      "Column: popularity\n",
      "0      6312\n",
      "50     5415\n",
      "53     5414\n",
      "51     5401\n",
      "52     5342\n",
      "       ... \n",
      "96        8\n",
      "94        7\n",
      "99        4\n",
      "98        3\n",
      "100       2\n",
      "Name: popularity, Length: 101, dtype: int64\n",
      "--------------------\n",
      "Column: acousticness\n",
      "0.995000    851\n",
      "0.994000    701\n",
      "0.992000    682\n",
      "0.993000    646\n",
      "0.991000    597\n",
      "           ... \n",
      "0.000005      1\n",
      "0.000007      1\n",
      "0.000098      1\n",
      "0.000083      1\n",
      "0.000009      1\n",
      "Name: acousticness, Length: 4734, dtype: int64\n",
      "--------------------\n",
      "Column: danceability\n",
      "0.5970    558\n",
      "0.5470    544\n",
      "0.6100    542\n",
      "0.5890    542\n",
      "0.6220    540\n",
      "         ... \n",
      "0.0584      1\n",
      "0.0577      1\n",
      "0.0570      1\n",
      "0.0878      1\n",
      "0.0596      1\n",
      "Name: danceability, Length: 1295, dtype: int64\n",
      "--------------------\n",
      "Column: duration_ms\n",
      "240000    138\n",
      "180000    120\n",
      "192000    115\n",
      "216000     99\n",
      "200000     85\n",
      "         ... \n",
      "258851      1\n",
      "238377      1\n",
      "164064      1\n",
      "244522      1\n",
      "262144      1\n",
      "Name: duration_ms, Length: 70749, dtype: int64\n",
      "--------------------\n",
      "Column: energy\n",
      "0.721000    417\n",
      "0.675000    403\n",
      "0.720000    392\n",
      "0.686000    389\n",
      "0.738000    389\n",
      "           ... \n",
      "0.002230      1\n",
      "0.000216      1\n",
      "0.006110      1\n",
      "0.009910      1\n",
      "0.007330      1\n",
      "Name: energy, Length: 2517, dtype: int64\n",
      "--------------------\n",
      "Column: instrumentalness\n",
      "0.00000    79236\n",
      "0.91200      235\n",
      "0.91000      230\n",
      "0.91800      222\n",
      "0.92300      222\n",
      "           ...  \n",
      "0.00966        1\n",
      "0.99900        1\n",
      "0.00667        1\n",
      "0.99800        1\n",
      "0.00888        1\n",
      "Name: instrumentalness, Length: 5400, dtype: int64\n",
      "--------------------\n",
      "Column: key\n",
      "C     27583\n",
      "G     26390\n",
      "D     24077\n",
      "C#    23201\n",
      "A     22671\n",
      "F     20279\n",
      "B     17661\n",
      "E     17390\n",
      "A#    15526\n",
      "F#    15222\n",
      "G#    15159\n",
      "D#     7566\n",
      "Name: key, dtype: int64\n",
      "--------------------\n",
      "Column: liveness\n",
      "0.1110    2860\n",
      "0.1100    2702\n",
      "0.1080    2608\n",
      "0.1090    2537\n",
      "0.1070    2451\n",
      "          ... \n",
      "0.0240       1\n",
      "0.0185       1\n",
      "0.0200       1\n",
      "0.0177       1\n",
      "0.0143       1\n",
      "Name: liveness, Length: 1732, dtype: int64\n",
      "--------------------\n",
      "Column: loudness\n",
      "-5.318     57\n",
      "-5.460     52\n",
      "-5.131     51\n",
      "-5.428     51\n",
      "-6.611     50\n",
      "           ..\n",
      "-31.696     1\n",
      "-38.267     1\n",
      "-45.192     1\n",
      "-28.588     1\n",
      "-1.494      1\n",
      "Name: loudness, Length: 27923, dtype: int64\n",
      "--------------------\n",
      "Column: mode\n",
      "Major    151744\n",
      "Minor     80981\n",
      "Name: mode, dtype: int64\n",
      "--------------------\n",
      "Column: speechiness\n",
      "0.0374    663\n",
      "0.0332    654\n",
      "0.0337    652\n",
      "0.0363    650\n",
      "0.0343    642\n",
      "         ... \n",
      "0.6070      1\n",
      "0.6880      1\n",
      "0.6620      1\n",
      "0.6750      1\n",
      "0.6670      1\n",
      "Name: speechiness, Length: 1641, dtype: int64\n",
      "--------------------\n",
      "Column: tempo\n",
      "120.016    61\n",
      "100.003    60\n",
      "100.014    60\n",
      "120.008    59\n",
      "120.003    59\n",
      "           ..\n",
      "82.571      1\n",
      "94.596      1\n",
      "62.067      1\n",
      "91.555      1\n",
      "110.206     1\n",
      "Name: tempo, Length: 78512, dtype: int64\n",
      "--------------------\n",
      "Column: time_signature\n",
      "4/4    200760\n",
      "3/4     24111\n",
      "5/4      5238\n",
      "1/4      2608\n",
      "0/4         8\n",
      "Name: time_signature, dtype: int64\n",
      "--------------------\n",
      "Column: valence\n",
      "0.9610    479\n",
      "0.9620    403\n",
      "0.9630    368\n",
      "0.3700    363\n",
      "0.3580    363\n",
      "         ... \n",
      "0.0232      1\n",
      "0.0209      1\n",
      "0.9950      1\n",
      "0.0227      1\n",
      "0.0180      1\n",
      "Name: valence, Length: 1692, dtype: int64\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#looking at different values contained within columns\n",
    "for col in df.columns:\n",
    "    print(f\"Column: {col}\")\n",
    "    print(df[col].value_counts())\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple things that stand out in the value counts of the columns. First one is that we have the \"Children's Music\" genre showing up twice and we have duplicated values in the track_id column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRUB/EXPLORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing \"Children's Music\" Character Discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:46:52.936695Z",
     "start_time": "2021-05-27T15:46:52.892722Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comedy              9681\n",
       "Soundtrack          9646\n",
       "Indie               9543\n",
       "Jazz                9441\n",
       "Pop                 9386\n",
       "Electronic          9377\n",
       "Children’s Music    9353\n",
       "Folk                9299\n",
       "Hip-Hop             9295\n",
       "Rock                9272\n",
       "Alternative         9263\n",
       "Classical           9256\n",
       "Rap                 9232\n",
       "World               9096\n",
       "Soul                9089\n",
       "Blues               9023\n",
       "R&B                 8992\n",
       "Anime               8936\n",
       "Reggaeton           8927\n",
       "Ska                 8874\n",
       "Reggae              8771\n",
       "Dance               8701\n",
       "Country             8664\n",
       "Opera               8280\n",
       "Movie               7806\n",
       "Children's Music    5403\n",
       "A Capella            119\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 types of \"Children's Music\" values in the genres due to the character used for apostrophe. Since both of these values are meant to show the same thing we need to merge them and achieve consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:46:52.984666Z",
     "start_time": "2021-05-27T15:46:52.941692Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df['genre']==\"Children’s Music\",'genre']=\"Children's Music\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:46:53.030641Z",
     "start_time": "2021-05-27T15:46:52.990663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Children's Music    14756\n",
       "Comedy               9681\n",
       "Soundtrack           9646\n",
       "Indie                9543\n",
       "Jazz                 9441\n",
       "Pop                  9386\n",
       "Electronic           9377\n",
       "Folk                 9299\n",
       "Hip-Hop              9295\n",
       "Rock                 9272\n",
       "Alternative          9263\n",
       "Classical            9256\n",
       "Rap                  9232\n",
       "World                9096\n",
       "Soul                 9089\n",
       "Blues                9023\n",
       "R&B                  8992\n",
       "Anime                8936\n",
       "Reggaeton            8927\n",
       "Ska                  8874\n",
       "Reggae               8771\n",
       "Dance                8701\n",
       "Country              8664\n",
       "Opera                8280\n",
       "Movie                7806\n",
       "A Capella             119\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verifying that the issue has been resolved\n",
    "df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:46:53.124119Z",
     "start_time": "2021-05-27T15:46:53.034639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre               0\n",
       "artist_name         0\n",
       "track_name          0\n",
       "track_id            0\n",
       "popularity          0\n",
       "acousticness        0\n",
       "danceability        0\n",
       "duration_ms         0\n",
       "energy              0\n",
       "instrumentalness    0\n",
       "key                 0\n",
       "liveness            0\n",
       "loudness            0\n",
       "mode                0\n",
       "speechiness         0\n",
       "tempo               0\n",
       "time_signature      0\n",
       "valence             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have any missing values in our columns so we will move onto check for duplicated rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Duplicated Tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to take a look and find all duplicated tracks by using their unique id numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:46:53.218545Z",
     "start_time": "2021-05-27T15:46:53.126280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>Alternative</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>Go To Town</td>\n",
       "      <td>6iOvnACn4ChlAw4lWUU4dd</td>\n",
       "      <td>64</td>\n",
       "      <td>0.07160</td>\n",
       "      <td>0.710</td>\n",
       "      <td>217813</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>C</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>-2.474</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>169.944</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>Alternative</td>\n",
       "      <td>Frank Ocean</td>\n",
       "      <td>Seigfried</td>\n",
       "      <td>1BViPjTT585XAhkUUrkts0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.97500</td>\n",
       "      <td>0.377</td>\n",
       "      <td>334570</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>E</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>-11.165</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>125.004</td>\n",
       "      <td>5/4</td>\n",
       "      <td>0.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>Alternative</td>\n",
       "      <td>Frank Ocean</td>\n",
       "      <td>Bad Religion</td>\n",
       "      <td>2pMPWE7PJH1PizfgGRMnR9</td>\n",
       "      <td>56</td>\n",
       "      <td>0.77900</td>\n",
       "      <td>0.276</td>\n",
       "      <td>175453</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0728</td>\n",
       "      <td>-7.684</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>81.977</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>Alternative</td>\n",
       "      <td>Steve Lacy</td>\n",
       "      <td>Some</td>\n",
       "      <td>4riDfclV7kPDT9D58FpmHd</td>\n",
       "      <td>58</td>\n",
       "      <td>0.00548</td>\n",
       "      <td>0.784</td>\n",
       "      <td>118393</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>G</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>-6.417</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>104.010</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>Alternative</td>\n",
       "      <td>tobi lou</td>\n",
       "      <td>Buff Baby</td>\n",
       "      <td>1F1QmI8TMHir9SUFrooq5F</td>\n",
       "      <td>59</td>\n",
       "      <td>0.19000</td>\n",
       "      <td>0.736</td>\n",
       "      <td>215385</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>F</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>-8.636</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>156.002</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232715</th>\n",
       "      <td>Soul</td>\n",
       "      <td>Emily King</td>\n",
       "      <td>Down</td>\n",
       "      <td>5cA0vB8c9FMOVDWyJHgf26</td>\n",
       "      <td>42</td>\n",
       "      <td>0.55000</td>\n",
       "      <td>0.394</td>\n",
       "      <td>281853</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>E</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>-13.617</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>90.831</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232718</th>\n",
       "      <td>Soul</td>\n",
       "      <td>Muddy Waters</td>\n",
       "      <td>I Just Want To Make Love To You - Electric Mud...</td>\n",
       "      <td>2HFczeynfKGiM9KF2z2K7K</td>\n",
       "      <td>43</td>\n",
       "      <td>0.01360</td>\n",
       "      <td>0.294</td>\n",
       "      <td>258267</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.004820</td>\n",
       "      <td>C</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>-7.167</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>176.402</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232720</th>\n",
       "      <td>Soul</td>\n",
       "      <td>Slave</td>\n",
       "      <td>Son Of Slide</td>\n",
       "      <td>2XGLdVl7lGeq8ksM6Al7jT</td>\n",
       "      <td>39</td>\n",
       "      <td>0.00384</td>\n",
       "      <td>0.687</td>\n",
       "      <td>326240</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>-10.626</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>115.542</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232722</th>\n",
       "      <td>Soul</td>\n",
       "      <td>Muddy Waters</td>\n",
       "      <td>(I'm Your) Hoochie Coochie Man</td>\n",
       "      <td>2ziWXUmQLrXTiYjCg2fZ2t</td>\n",
       "      <td>47</td>\n",
       "      <td>0.90100</td>\n",
       "      <td>0.517</td>\n",
       "      <td>166960</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>-8.282</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>84.135</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232723</th>\n",
       "      <td>Soul</td>\n",
       "      <td>R.LUM.R</td>\n",
       "      <td>With My Words</td>\n",
       "      <td>6EFsue2YbIG4Qkq8Zr9Rir</td>\n",
       "      <td>44</td>\n",
       "      <td>0.26200</td>\n",
       "      <td>0.745</td>\n",
       "      <td>222442</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>-7.137</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>100.031</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55951 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              genre   artist_name  \\\n",
       "1348    Alternative      Doja Cat   \n",
       "1385    Alternative   Frank Ocean   \n",
       "1452    Alternative   Frank Ocean   \n",
       "1554    Alternative    Steve Lacy   \n",
       "1634    Alternative      tobi lou   \n",
       "...             ...           ...   \n",
       "232715         Soul    Emily King   \n",
       "232718         Soul  Muddy Waters   \n",
       "232720         Soul         Slave   \n",
       "232722         Soul  Muddy Waters   \n",
       "232723         Soul       R.LUM.R   \n",
       "\n",
       "                                               track_name  \\\n",
       "1348                                           Go To Town   \n",
       "1385                                            Seigfried   \n",
       "1452                                         Bad Religion   \n",
       "1554                                                 Some   \n",
       "1634                                            Buff Baby   \n",
       "...                                                   ...   \n",
       "232715                                               Down   \n",
       "232718  I Just Want To Make Love To You - Electric Mud...   \n",
       "232720                                       Son Of Slide   \n",
       "232722                     (I'm Your) Hoochie Coochie Man   \n",
       "232723                                      With My Words   \n",
       "\n",
       "                      track_id  popularity  acousticness  danceability  \\\n",
       "1348    6iOvnACn4ChlAw4lWUU4dd          64       0.07160         0.710   \n",
       "1385    1BViPjTT585XAhkUUrkts0          61       0.97500         0.377   \n",
       "1452    2pMPWE7PJH1PizfgGRMnR9          56       0.77900         0.276   \n",
       "1554    4riDfclV7kPDT9D58FpmHd          58       0.00548         0.784   \n",
       "1634    1F1QmI8TMHir9SUFrooq5F          59       0.19000         0.736   \n",
       "...                        ...         ...           ...           ...   \n",
       "232715  5cA0vB8c9FMOVDWyJHgf26          42       0.55000         0.394   \n",
       "232718  2HFczeynfKGiM9KF2z2K7K          43       0.01360         0.294   \n",
       "232720  2XGLdVl7lGeq8ksM6Al7jT          39       0.00384         0.687   \n",
       "232722  2ziWXUmQLrXTiYjCg2fZ2t          47       0.90100         0.517   \n",
       "232723  6EFsue2YbIG4Qkq8Zr9Rir          44       0.26200         0.745   \n",
       "\n",
       "        duration_ms  energy  instrumentalness key  liveness  loudness   mode  \\\n",
       "1348         217813   0.710          0.000001   C    0.2060    -2.474  Major   \n",
       "1385         334570   0.255          0.000208   E    0.1020   -11.165  Minor   \n",
       "1452         175453   0.358          0.000003   A    0.0728    -7.684  Major   \n",
       "1554         118393   0.554          0.254000   G    0.0995    -6.417  Major   \n",
       "1634         215385   0.643          0.000000   F    0.1060    -8.636  Major   \n",
       "...             ...     ...               ...  ..       ...       ...    ...   \n",
       "232715       281853   0.346          0.000002   E    0.1290   -13.617  Major   \n",
       "232718       258267   0.739          0.004820   C    0.1380    -7.167  Major   \n",
       "232720       326240   0.714          0.544000   D    0.0845   -10.626  Major   \n",
       "232722       166960   0.419          0.000000   D    0.0945    -8.282  Major   \n",
       "232723       222442   0.704          0.000000   A    0.3330    -7.137  Major   \n",
       "\n",
       "        speechiness    tempo time_signature  valence  \n",
       "1348         0.0579  169.944            4/4    0.700  \n",
       "1385         0.0387  125.004            5/4    0.370  \n",
       "1452         0.0443   81.977            4/4    0.130  \n",
       "1554         0.0300  104.010            4/4    0.634  \n",
       "1634         0.0461  156.002            4/4    0.599  \n",
       "...             ...      ...            ...      ...  \n",
       "232715       0.0635   90.831            4/4    0.436  \n",
       "232718       0.0434  176.402            4/4    0.945  \n",
       "232720       0.0316  115.542            4/4    0.962  \n",
       "232722       0.1480   84.135            4/4    0.813  \n",
       "232723       0.1460  100.031            4/4    0.489  \n",
       "\n",
       "[55951 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['track_id'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 55,951 duplicated rows that we need to address. Before we can address these duplications though we need to see what the cause of the duplicates are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:46:53.265503Z",
     "start_time": "2021-05-27T15:46:53.220529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>R&amp;B</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>Go To Town</td>\n",
       "      <td>6iOvnACn4ChlAw4lWUU4dd</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.71</td>\n",
       "      <td>217813</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>C</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-2.474</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>169.944</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>Alternative</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>Go To Town</td>\n",
       "      <td>6iOvnACn4ChlAw4lWUU4dd</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.71</td>\n",
       "      <td>217813</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>C</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-2.474</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>169.944</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77710</th>\n",
       "      <td>Children's Music</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>Go To Town</td>\n",
       "      <td>6iOvnACn4ChlAw4lWUU4dd</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.71</td>\n",
       "      <td>217813</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>C</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-2.474</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>169.944</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93651</th>\n",
       "      <td>Indie</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>Go To Town</td>\n",
       "      <td>6iOvnACn4ChlAw4lWUU4dd</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.71</td>\n",
       "      <td>217813</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>C</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-2.474</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>169.944</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113770</th>\n",
       "      <td>Pop</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>Go To Town</td>\n",
       "      <td>6iOvnACn4ChlAw4lWUU4dd</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.71</td>\n",
       "      <td>217813</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>C</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-2.474</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>169.944</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   genre artist_name  track_name                track_id  \\\n",
       "257                  R&B    Doja Cat  Go To Town  6iOvnACn4ChlAw4lWUU4dd   \n",
       "1348         Alternative    Doja Cat  Go To Town  6iOvnACn4ChlAw4lWUU4dd   \n",
       "77710   Children's Music    Doja Cat  Go To Town  6iOvnACn4ChlAw4lWUU4dd   \n",
       "93651              Indie    Doja Cat  Go To Town  6iOvnACn4ChlAw4lWUU4dd   \n",
       "113770               Pop    Doja Cat  Go To Town  6iOvnACn4ChlAw4lWUU4dd   \n",
       "\n",
       "        popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "257             64        0.0716          0.71       217813    0.71   \n",
       "1348            64        0.0716          0.71       217813    0.71   \n",
       "77710           64        0.0716          0.71       217813    0.71   \n",
       "93651           64        0.0716          0.71       217813    0.71   \n",
       "113770          64        0.0716          0.71       217813    0.71   \n",
       "\n",
       "        instrumentalness key  liveness  loudness   mode  speechiness    tempo  \\\n",
       "257             0.000001   C     0.206    -2.474  Major       0.0579  169.944   \n",
       "1348            0.000001   C     0.206    -2.474  Major       0.0579  169.944   \n",
       "77710           0.000001   C     0.206    -2.474  Major       0.0579  169.944   \n",
       "93651           0.000001   C     0.206    -2.474  Major       0.0579  169.944   \n",
       "113770          0.000001   C     0.206    -2.474  Major       0.0579  169.944   \n",
       "\n",
       "       time_signature  valence  \n",
       "257               4/4      0.7  \n",
       "1348              4/4      0.7  \n",
       "77710             4/4      0.7  \n",
       "93651             4/4      0.7  \n",
       "113770            4/4      0.7  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking rows for duplicated ids to see differences\n",
    "df[df['track_id']=='6iOvnACn4ChlAw4lWUU4dd'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:46:53.312476Z",
     "start_time": "2021-05-27T15:46:53.267502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179212</th>\n",
       "      <td>Jazz</td>\n",
       "      <td>Slave</td>\n",
       "      <td>Son Of Slide</td>\n",
       "      <td>2XGLdVl7lGeq8ksM6Al7jT</td>\n",
       "      <td>39</td>\n",
       "      <td>0.00384</td>\n",
       "      <td>0.687</td>\n",
       "      <td>326240</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.544</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>-10.626</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>115.542</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232720</th>\n",
       "      <td>Soul</td>\n",
       "      <td>Slave</td>\n",
       "      <td>Son Of Slide</td>\n",
       "      <td>2XGLdVl7lGeq8ksM6Al7jT</td>\n",
       "      <td>39</td>\n",
       "      <td>0.00384</td>\n",
       "      <td>0.687</td>\n",
       "      <td>326240</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.544</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>-10.626</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>115.542</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       genre artist_name    track_name                track_id  popularity  \\\n",
       "179212  Jazz       Slave  Son Of Slide  2XGLdVl7lGeq8ksM6Al7jT          39   \n",
       "232720  Soul       Slave  Son Of Slide  2XGLdVl7lGeq8ksM6Al7jT          39   \n",
       "\n",
       "        acousticness  danceability  duration_ms  energy  instrumentalness key  \\\n",
       "179212       0.00384         0.687       326240   0.714             0.544   D   \n",
       "232720       0.00384         0.687       326240   0.714             0.544   D   \n",
       "\n",
       "        liveness  loudness   mode  speechiness    tempo time_signature  \\\n",
       "179212    0.0845   -10.626  Major       0.0316  115.542            4/4   \n",
       "232720    0.0845   -10.626  Major       0.0316  115.542            4/4   \n",
       "\n",
       "        valence  \n",
       "179212    0.962  \n",
       "232720    0.962  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['track_id']=='2XGLdVl7lGeq8ksM6Al7jT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:46:53.360468Z",
     "start_time": "2021-05-27T15:46:53.314476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48555</th>\n",
       "      <td>Blues</td>\n",
       "      <td>Muddy Waters</td>\n",
       "      <td>I Just Want To Make Love To You - Electric Mud...</td>\n",
       "      <td>2HFczeynfKGiM9KF2z2K7K</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.294</td>\n",
       "      <td>258267</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.00482</td>\n",
       "      <td>C</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-7.167</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>176.402</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232718</th>\n",
       "      <td>Soul</td>\n",
       "      <td>Muddy Waters</td>\n",
       "      <td>I Just Want To Make Love To You - Electric Mud...</td>\n",
       "      <td>2HFczeynfKGiM9KF2z2K7K</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.294</td>\n",
       "      <td>258267</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.00482</td>\n",
       "      <td>C</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-7.167</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>176.402</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        genre   artist_name  \\\n",
       "48555   Blues  Muddy Waters   \n",
       "232718   Soul  Muddy Waters   \n",
       "\n",
       "                                               track_name  \\\n",
       "48555   I Just Want To Make Love To You - Electric Mud...   \n",
       "232718  I Just Want To Make Love To You - Electric Mud...   \n",
       "\n",
       "                      track_id  popularity  acousticness  danceability  \\\n",
       "48555   2HFczeynfKGiM9KF2z2K7K          35        0.0136         0.294   \n",
       "232718  2HFczeynfKGiM9KF2z2K7K          43        0.0136         0.294   \n",
       "\n",
       "        duration_ms  energy  instrumentalness key  liveness  loudness   mode  \\\n",
       "48555        258267   0.739           0.00482   C     0.138    -7.167  Major   \n",
       "232718       258267   0.739           0.00482   C     0.138    -7.167  Major   \n",
       "\n",
       "        speechiness    tempo time_signature  valence  \n",
       "48555        0.0434  176.402            4/4    0.945  \n",
       "232718       0.0434  176.402            4/4    0.945  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['track_id']=='2HFczeynfKGiM9KF2z2K7K']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that most of the attributes of the duplicated songs are the same except for 'popularity' and 'genre'. The 'popularity' column can be aggregated since it is a numerical column but the categorical column of 'genre' is a little bit trickier. What makes the most sense in this case would be to create different columns with the genre names and display with binary values whether a song belongs to that genre or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:46:53.392444Z",
     "start_time": "2021-05-27T15:46:53.362462Z"
    }
   },
   "outputs": [],
   "source": [
    "#generating a list with the genre names\n",
    "genre_list = list(df['genre'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:46:53.790200Z",
     "start_time": "2021-05-27T15:46:53.394429Z"
    }
   },
   "outputs": [],
   "source": [
    "#creating the genre columns using the genre list\n",
    "for genre in genre_list:\n",
    "    df[genre] = (df['genre']==genre).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.741Z"
    }
   },
   "outputs": [],
   "source": [
    "#grouping by track_id number to get rid of duplicates and keeping the maximum values in each column.\n",
    "df=df.groupby(['track_id']).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we created the genre columns and merged the duplicated values keeping the maximum value in each column. This makes sense since the track that is being listened to is the same one. For example, if a track had popularity scores of 15, 25, 38 and 42 in its duplicated rows, we are keeping the best value of 42 by taking the max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.747Z"
    }
   },
   "outputs": [],
   "source": [
    "#removing redundant genre column\n",
    "df.drop('genre', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.752Z"
    }
   },
   "outputs": [],
   "source": [
    "#verifying that duplicates have been eliminated\n",
    "df[df.index =='6iOvnACn4ChlAw4lWUU4dd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfully addressed the duplicates of each track by aggregating them to a single row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.757Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 176,774 unique tracks in our dataset (down from 232,725)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering - is_popular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our goal is to be able to identify which tracks will be popular, we need to feature engineer a new column by binarizing the popularity column. To be able to do this, we need to decide on a cut-off point of popularity score which if a song stays above this cut-off point it will be considered \"popular\" and if it stays below it will be considered \"not popular\". We can start off by taking a look at the distribution of the popularity score distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.763Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.768Z"
    }
   },
   "outputs": [],
   "source": [
    "#creating a histogram to see distribution of popularity scores in the dataset.\n",
    "sns.histplot(df['popularity'], bins='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above histogram we see that we have a bimodal distribution. One of the peaks is at 0, and the other one seems to be around 40. In order to better decide what's popular, we can take a look at the Top 50 songs' popularity scores (this data is also from 2019 similar to our main dataset to keep the analysis consistent.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 50 Songs - 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.777Z"
    }
   },
   "outputs": [],
   "source": [
    "#data from https://www.kaggle.com/leonardopena/top50spotify2019\n",
    "df_50 = pd.read_csv('data/top50.csv', encoding='latin1', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.782Z"
    }
   },
   "outputs": [],
   "source": [
    "df_50.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.787Z"
    }
   },
   "outputs": [],
   "source": [
    "#displaying stats information of Top 50 songs\n",
    "df_50['Popularity'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to our histogram we can draw vertical lines to see where these values fall into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.793Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.histplot(df['popularity'], bins='auto', ax=ax)\n",
    "stats=['mean', '50%', 'min', 'max']\n",
    "for stat in stats:\n",
    "    ax.vlines(x=df_50['Popularity'].describe()[stat], ymin=0, ymax=6000, linestyles='dashed', colors='red', label=stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there was a range of popularity scores in the Top 50 songs between 70 and 95. Which means that any song that is above a 70 theoretically could be a popular song. It doesn't make sense to use median or mean scores for our cutoff point in this case since then we would be disregarding all the songs that had lower values than 87.5 or 88 as unpopular which is untrue. However, before we can establish the cutoff point we need to acknowledge that we are basing it off of only 50 datapoints which is not a lot. It may be good to take a look at Top 100 songs instead of 50 to get a better sample size of popular songs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 100 Songs - 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.799Z"
    }
   },
   "outputs": [],
   "source": [
    "#data from https://www.kaggle.com/reach2ashish/top-100-spotify-songs-2019\n",
    "df_100 = pd.read_csv('data/spotify_top_100_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.804Z"
    }
   },
   "outputs": [],
   "source": [
    "df_100['popularity '].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum value of 4 for the popularity score on the Top 100 Songs chart seems like an outlier. Next, we'll visualize the spread of this column to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.809Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.histplot(df_100['popularity '], bins='auto', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we imagined the scores within the range 0-25 seem like outliers. We can remove outliers from this dataset with the IQR method to get a better perspective on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.813Z"
    }
   },
   "outputs": [],
   "source": [
    "#Outlier Removal with the IQR method\n",
    "\n",
    "def find_outliers_IQR(data):\n",
    "    \"\"\"Use Tukey's Method of outlier removal AKA InterQuartile-Range Rule\n",
    "    and return boolean series where True indicates it is an outlier.\n",
    "    - Calculates the range between the 75% and 25% quartiles\n",
    "    - Outliers fall outside upper and lower limits, using a treshold of  1.5*IQR the 75% and 25% quartiles.\n",
    "\n",
    "    IQR Range Calculation:    \n",
    "        res = df.describe()\n",
    "        IQR = res['75%'] -  res['25%']\n",
    "        lower_limit = res['25%'] - 1.5*IQR\n",
    "        upper_limit = res['75%'] + 1.5*IQR\n",
    "\n",
    "    Args:\n",
    "        data (Series,or ndarray): data to test for outliers.\n",
    "\n",
    "    Returns:\n",
    "        [boolean Series]: A True/False for each row use to slice outliers.\n",
    "        \n",
    "    EXAMPLE USE: \n",
    "    >> idx_outs = find_outliers_df(df['AdjustedCompensation'])\n",
    "    >> good_data = df[~idx_outs].copy()\n",
    "    \n",
    "    function snippet from Flatiron School Phase #2 Py Files.\n",
    "    URL = https://github.com/flatiron-school/Online-DS-FT-022221-Cohort-Notes/blob/master/py_files/functions_SG.py\n",
    "    \n",
    "    \"\"\"\n",
    "    df_b=data\n",
    "    res= df_b.describe()\n",
    "\n",
    "    IQR = res['75%'] -  res['25%']\n",
    "    lower_limit = res['25%'] - 1.5*IQR\n",
    "    upper_limit = res['75%'] + 1.5*IQR\n",
    "\n",
    "    idx_outs = (df_b>upper_limit) | (df_b<lower_limit)\n",
    "\n",
    "    return idx_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.818Z"
    }
   },
   "outputs": [],
   "source": [
    "#removing outliers from the popularity column\n",
    "df_100 = df_100[find_outliers_IQR(df_100['popularity '])==False]\n",
    "#displaying minimum & maxium values in popularity column \n",
    "print(\"Minimum:\", df_100['popularity '].min())\n",
    "print(\"Maximum:\", df_100['popularity '].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.823Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.histplot(df_100['popularity '], bins=15, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.827Z"
    }
   },
   "outputs": [],
   "source": [
    "#visualizing the min and max popularity scores on the overall dataset histogram\n",
    "fig, ax = plt.subplots()\n",
    "sns.histplot(df['popularity'], bins='auto', ax=ax)\n",
    "ax.vlines(x=df_100['popularity '].min(), ymin=0, ymax=6000, linestyles='dashed', colors='red', label='min')\n",
    "ax.vlines(x=df_100['popularity '].max(), ymin=0, ymax=6000, linestyles='dashed', colors='red', label='max')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can expect to see, the top 100 songs have a wider range and therefore a lower popularity score threshold compared to the top 50 songs. We will be defining a song being popular as being Top 100 worthy and therefore will establish our cutoff point at 58."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.833Z"
    }
   },
   "outputs": [],
   "source": [
    "#creating is_popular column with our cutoff point\n",
    "df['is_popular']=(df['popularity']>=58).astype('int')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.838Z"
    }
   },
   "outputs": [],
   "source": [
    "#dropping popularity score column since we will not be using it\n",
    "df.drop(['popularity', 'artist_name', 'track_name'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dropped popularity scores since we already binarized that column, but additionally we are dropping 'artist_name' and 'track_name' since we are looking at the anatomy of a song and not who sings it or what it's called. The goal is to identify songs that will become popular without being affected by the artist's name since we would also like to find songs from up-and-coming artists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding the Categorical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have categorical columns that need one hot encoding. Namely, these columns are 'key', 'mode' and 'time_signature'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.845Z"
    }
   },
   "outputs": [],
   "source": [
    "#Check to see how many more columns we will be creating by OHE the cat_cols.\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be creating 2 (mode) + 5 (time_signature) + key (12) - 3 (drop_first) = 16 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.850Z"
    }
   },
   "outputs": [],
   "source": [
    "#define categorical columns\n",
    "cat_cols = ['key', 'mode', 'time_signature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.855Z"
    }
   },
   "outputs": [],
   "source": [
    "#One hot encoding the dataframe\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder=OneHotEncoder(sparse=False, drop='first')\n",
    "data_ohe = encoder.fit_transform(df[cat_cols])\n",
    "df_ohe = pd.DataFrame(data_ohe, columns=encoder.get_feature_names(cat_cols), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.864Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "df_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.871Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ohe = pd.concat([df.drop(cat_cols, axis=1), df_ohe], axis=1)\n",
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dataframe scrubbed and one hot encoded we can move onto the modelling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.878Z"
    }
   },
   "outputs": [],
   "source": [
    "#splitting the data to training and test sets in order to be able to measure performance\n",
    "from sklearn.model_selection import train_test_split\n",
    "y=df_ohe['is_popular']\n",
    "X=df_ohe.drop('is_popular',axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model we will be generating is a dummy classifier. We will be comparing our models' success to each other but also to this baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1 - Baseline - Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.886Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "clf_dummy = DummyClassifier(random_state=42)\n",
    "clf_dummy.fit(X_train, y_train)\n",
    "y_pred = clf_dummy.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a function that will show us the classification report, the confusion matrix as well as the ROC curve to be able to evaluate our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.891Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, plot_confusion_matrix, plot_roc_curve\n",
    "\n",
    "def classification(y_true, y_pred, X, clf):\n",
    "    \"\"\"This function shows the classification report,\n",
    "    the confusion matrix as well as the ROC curve for evaluation of model quality.\n",
    "    \n",
    "    y_true: Correct y values, typically y_test that comes from the train_test_split performed at the beginning of model development.\n",
    "    y_pred: Predicted y values by the model.\n",
    "    clf: classifier model that was fit to training data.\n",
    "    X: X_test values\"\"\"\n",
    "    \n",
    "    #Classification report\n",
    "    print(\"CLASSIFICATION REPORT\")\n",
    "    print(\"------------------------------------------\")\n",
    "    print(classification_report(y_true=y_true, y_pred=y_pred))\n",
    "    \n",
    "    #Creating a figure/axes for confusion matrix and ROC curve\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "    \n",
    "    #Plotting the normalized confusion matrix\n",
    "    plot_confusion_matrix(estimator=clf, X=X, y_true=y_true, cmap='Blues', normalize='true', ax=ax[0])\n",
    "    \n",
    "    #Plotting the ROC curve\n",
    "    plot_roc_curve(estimator=clf, X=X, y=y_true, ax=ax[1])\n",
    "    \n",
    "    #Plotting the 50-50 guessing plot for reference\n",
    "    ax[1].plot([0,1], [0,1], ls='--', color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.896Z"
    }
   },
   "outputs": [],
   "source": [
    "classification(y_test, y_pred, X_test, clf_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.901Z"
    }
   },
   "outputs": [],
   "source": [
    "#class imbalance percentages\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dummy classifier correctly predicted 89% of the unpopular songs as unpopular; however, it correctly predicted only 11% of the popular songs as popular and instead classified 89% of them as unpopular as well. We clearly have a class imbalance problem where approximately 88% of our data is not popular and only about 11% of it is. To address this we can SMOTE the training data and see if training a model with this method would improve our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Class Imbalance with SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.907Z"
    }
   },
   "outputs": [],
   "source": [
    "#looking at column names to extract categorical column indices for SMOTENC\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.912Z"
    }
   },
   "outputs": [],
   "source": [
    "#creating a list of categorical column indices\n",
    "cat_cols = list(range(10, len(X.columns)))\n",
    "X.columns[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.917Z"
    }
   },
   "outputs": [],
   "source": [
    "#Using SMOTENC to address class imbalance. We are not using SMOTE since we have categorical columns.\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "\n",
    "sm = SMOTENC(categorical_features=cat_cols, random_state=42)\n",
    "\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "y_train_sm.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we addressed our class imbalance problem, we can look at the performance of the dummy classifier model once again to use as our baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.923Z"
    }
   },
   "outputs": [],
   "source": [
    "#fitting Dummy Classifier to data without the class imbalance problem to serve as a true baseline\n",
    "clf_dummy_sm = DummyClassifier(random_state=42)\n",
    "clf_dummy_sm.fit(X_train_sm, y_train_sm)\n",
    "y_pred = clf_dummy_sm.predict(X_test)\n",
    "classification(y_test, y_pred, X_test, clf_dummy_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that the dummy classifier is essentially flipping a coin and guessing whether a song is popular or not which is not very useful. However, this serves as a great baseline for our other models to be evaluated against."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2 - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model we will be developing is the Random Forest classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.930Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Fitting RF Classifier to SMOTE'd data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "clf_rf.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "#Making predictions and evaluation.\n",
    "y_pred = clf_rf.predict(X_test)\n",
    "classification(y_test, y_pred, X_test, clf_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Random Forest model performs 48% better than the baseline classifier in predicting unpopular songs correctly and 9% better in predicting popular songs. The model may be overfitting, so to confirm we will look at the performance of the model with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.936Z"
    }
   },
   "outputs": [],
   "source": [
    "#Evaluating the model performance for the training data\n",
    "y_pred = clf_rf.predict(X_train_sm)\n",
    "classification(y_train_sm, y_pred, X_train_sm, clf_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is performing perfectly on the training data but not so much on the test data since it is overfitting to the training set. We need to tune our model to get more accurate results on unseen data. We will be using a grid search to optimize for the recall score. We are optimizing recall instead of other scores since we primarily care about correctly identifying a song that will be popular and we don't mind it if we pick a few songs that don't end up becoming popular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.942Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# clf = RandomForestClassifier()\n",
    "# grid = {'criterion': ['gini', 'entropy'], \n",
    "#         'max_depth': [10, 20, None],\n",
    "#         'min_samples_leaf': [1, 2, 3]\n",
    "#        }\n",
    "\n",
    "# gridsearch = GridSearchCV(estimator=clf, param_grid = grid, scoring='recall')\n",
    "\n",
    "# gridsearch.fit(X_train_sm,  y_train_sm)\n",
    "# gridsearch.best_params_\n",
    "# #Results: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.946Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_rf_tuned = RandomForestClassifier(criterion='entropy', max_depth=None, \n",
    "                                      min_samples_leaf=2, class_weight='balanced', \n",
    "                                      random_state=42)\n",
    "clf_rf_tuned.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "y_pred = clf_rf_tuned.predict(X_test)\n",
    "classification(y_test, y_pred, X_test, clf_rf_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the hyperparameters of our model improved the recall score for predicting popular songs by 1% (refer to Limitations & Next Steps section on the README document for more information). We can proceed with trying additional types of models to see if the recall score improves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #3 - XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.953Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fitting XGBoost classifier to training data and evaluating results\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf_xgb = XGBClassifier(random_state=42)\n",
    "clf_xgb.fit(X_train_sm, y_train_sm)\n",
    "y_pred = clf_xgb.predict(X_test)\n",
    "classification(y_test, y_pred, X_test, clf_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost model performed 13% better than the baseline model and 4% better than the random forest model in predicting popular songs right out of the box. We can see how it performs on the training data to see whether it is overfitting and try to tune it if it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.958Z"
    }
   },
   "outputs": [],
   "source": [
    "#Evaluating the model performance for the training data\n",
    "y_pred = clf_xgb.predict(X_train_sm)\n",
    "classification(y_train_sm, y_pred, X_train_sm, clf_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we see here that our model is overfitting the training data. We can run another gridsearch and tune our model to see if the recall score can be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.964Z"
    }
   },
   "outputs": [],
   "source": [
    "# grid = {\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [10, 20, None]\n",
    "#         }\n",
    "# gridsearch = GridSearchCV(estimator=clf_xgb, param_grid = grid, scoring='recall', n_jobs=-1, verbose=2)\n",
    "\n",
    "# gridsearch.fit(X_train_sm,  y_train_sm)\n",
    "# gridsearch.best_params_\n",
    "# # Results: {'learning_rate': 0.1, 'max_depth': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.968Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_xgb_tuned = XGBClassifier(learning_rate=0.1, max_depth=10, \n",
    "                              random_state=42)\n",
    "clf_xgb_tuned.fit(X_train_sm, y_train_sm)\n",
    "y_pred = clf_xgb_tuned.predict(X_test)\n",
    "classification(y_test, y_pred, X_test, clf_xgb_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning our model has led to an increase of performance in our recall score by 1%, so we are performing 14% better compared to our baseline Dummy Classifier model and 5% better than our tuned Random Forest model. Next we will try a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #4 - LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Logistic Regression models are potentially sensitive to outliers and need scaled data we will need to process our data one more time to remove outliers and scale it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.975Z"
    }
   },
   "outputs": [],
   "source": [
    "#separating out the numerical columns for outlier removal\n",
    "num_cols = list(X.columns[0:10])\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.980Z"
    }
   },
   "outputs": [],
   "source": [
    "#copying df for outlier removal\n",
    "df_ohe_clean = df_ohe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.987Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    df_ohe_clean = df_ohe_clean[find_outliers_IQR(df_ohe_clean[col])==False]\n",
    "    \n",
    "df_ohe_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.991Z"
    }
   },
   "outputs": [],
   "source": [
    "y=df_ohe_clean['is_popular']\n",
    "X=df_ohe_clean.drop('is_popular', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing Class Imbalance with SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:50.996Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again our data has a class imbalance issue so we will be using SMOTENC to address this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.003Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.007Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols = list(range(10,len(X_train.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.011Z"
    }
   },
   "outputs": [],
   "source": [
    "sm = SMOTENC(categorical_features=cat_cols, random_state=42)\n",
    "\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "y_train_sm.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.016Z"
    }
   },
   "outputs": [],
   "source": [
    "#Using Standard Scaler to scale the smote'd data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_sm_sc = scaler.fit_transform(X_train_sm)\n",
    "X_test_sc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.021Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "clf_logregcv = LogisticRegressionCV(cv=5, random_state=42)\n",
    "clf_logregcv.fit(X_train_sm_sc,  y_train_sm)\n",
    "y_pred = clf_logregcv.predict(X_test_sc)\n",
    "classification(y_test, y_pred, X_test_sc, clf_logregcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model has the same recall as our tuned XGBoost model for predicting popular songs while the recall score for predicting unpopular songs is 4% lower. Once again, we will check to see if the model is overfitting and tune the model if it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.025Z"
    }
   },
   "outputs": [],
   "source": [
    "#Evaluating the model performance for the training data\n",
    "y_pred = clf_logregcv.predict(X_train_sm_sc)\n",
    "classification(y_train_sm, y_pred, X_train_sm_sc, clf_logregcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is once again overfitting to the training data and performing very well on it but the model's performance drops significantly when we test it with the test data. In order to address this, we can once again perform a grid search and try to tune the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.032Z"
    }
   },
   "outputs": [],
   "source": [
    "# clf = LogisticRegressionCV(cv=5)\n",
    "# grid = {'penalty': ['l1','l2'],\n",
    "#         'solver': ['liblinear', 'lbfgs', 'sag', 'saga'],\n",
    "#         'class_weight': ['balanced', None],\n",
    "#         'Cs': [1e12, 10, 1, 0.1]\n",
    "#    }\n",
    "\n",
    "# gridsearch = GridSearchCV(estimator=clf, param_grid = grid, scoring='recall', n_jobs=-1)\n",
    "\n",
    "# gridsearch.fit(X_train_sm_sc,  y_train_sm)\n",
    "# gridsearch.best_params_\n",
    "# # {'Cs': 1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search returned 'l2' as the regularization method which is the Ridge regularization as well as a C value of 1. We will use these parameters on a new model to see if the recall score improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.037Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_logregcv_tuned = LogisticRegressionCV(cv=5, class_weight='balanced', Cs=1, \n",
    "                                          penalty='l2', solver='liblinear',\n",
    "                                          random_state=42)\n",
    "clf_logregcv_tuned.fit(X_train_sm_sc,  y_train_sm)\n",
    "y_pred = clf_logregcv_tuned.predict(X_test_sc)\n",
    "classification(y_test, y_pred, X_test_sc, clf_logregcv_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the parameters returned by our grid search did not seem to improve the recall score. This can potentially be due to the limitation of the model itself or more likely is the limitations of our dataset. We simply may not have enough data points to more accurately predict the popularity of a song."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iNTERPRET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have 3 tuned models, we can analyze which attributes they used in predicting whether a song was going to be popular or not and interpret these values. For this we will be looking at feature importances of each model and comparing them against each other to see if we can see any common threads between the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Feature Importances to Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.046Z"
    }
   },
   "outputs": [],
   "source": [
    "#accessing feature importance values of the tuned random forest model and sorting them\n",
    "rf_importances_df = pd.Series(clf_rf_tuned.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "#parsing the series to a dataframe\n",
    "rf_importances_df = rf_importances_df.reset_index()\n",
    "rf_importances_df.columns = ['RF-Attribute', 'RF-Importance']\n",
    "rf_importances_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T16:11:38.894310Z",
     "start_time": "2021-05-23T16:11:38.883338Z"
    }
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.054Z"
    }
   },
   "outputs": [],
   "source": [
    "#parsing feature importances to a series and sorting\n",
    "xgb_importances_df = pd.Series(clf_xgb_tuned.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "#parsing the series to a dataframe\n",
    "xgb_importances_df = xgb_importances_df.reset_index()\n",
    "xgb_importances_df.columns=['XGB-Attribute', 'XGB-Importance']\n",
    "xgb_importances_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.059Z"
    }
   },
   "outputs": [],
   "source": [
    "#accessing feature importance values of the tuned logistic regression model and sorting them\n",
    "logregcv_importances_df = pd.Series(clf_logregcv_tuned.coef_[0], index=X.columns).sort_values(ascending=False)\n",
    "#parsing the series to a dataframe\n",
    "logregcv_importances_df = logregcv_importances_df.reset_index()\n",
    "logregcv_importances_df.columns = ['LogReg-Attribute', 'LogReg-Importance']\n",
    "logregcv_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.067Z"
    }
   },
   "outputs": [],
   "source": [
    "#Concatenating feature importances into a single dataframe\n",
    "importances_df = pd.concat([rf_importances_df, xgb_importances_df, logregcv_importances_df], axis=1)\n",
    "importances_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.072Z"
    }
   },
   "outputs": [],
   "source": [
    "#plotting feature importances for all models for comparison\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(15,5))\n",
    "\n",
    "rf_importances_df = rf_importances_df.sort_values(by='RF-Importance', ascending=True).tail(10)\n",
    "ax[0].barh(rf_importances_df['RF-Attribute'], rf_importances_df['RF-Importance'])\n",
    "ax[0].set_title('Feature Importances: Random Forest')\n",
    "\n",
    "xgb_importances_df = xgb_importances_df.sort_values(by='XGB-Importance', ascending=True).tail(10)\n",
    "ax[1].barh(xgb_importances_df['XGB-Attribute'], xgb_importances_df['XGB-Importance'])\n",
    "ax[1].set_title('Feature Importances: XGBoost')\n",
    "\n",
    "logregcv_importances_df = logregcv_importances_df.sort_values(by='LogReg-Importance', ascending=True).tail(10)\n",
    "ax[2].barh(logregcv_importances_df['LogReg-Attribute'], logregcv_importances_df['LogReg-Importance'])\n",
    "ax[2].set_title('Feature Importances: LogisticRegressionCV')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the 3 models we built we can see that Genre of a song has the highest effect on the popularity of a song. On all 3 models, a song having Pop as its genre had the most impact on its popularity. This makes sense since Pop songs by nature are considered popular. Among the rest of the features shown above, different attribute scores such as danceability, energy, different genres and acousticness play a major role. Next, we can inspect the full gamut of the feature importances for logistic regression for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.077Z"
    }
   },
   "outputs": [],
   "source": [
    "logregcv_importances_df = pd.Series(clf_logregcv_tuned.coef_[0], index=X.columns).sort_values(ascending=False)\n",
    "#parsing the series to a dataframe\n",
    "logregcv_importances_df = logregcv_importances_df.reset_index()\n",
    "logregcv_importances_df.columns = ['Attribute', 'Importance']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,15))\n",
    "ax.barh(logregcv_importances_df['Attribute'], logregcv_importances_df['Importance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that while certain features like 'Pop', 'Rock' and 'danceability' positively affected the prediction, other features such as 'Ska', 'Anime' and 'key_G' negatively affected it. Next we can dive into our processed dataframe and explore some of these attributes for popular and unpopular songs to come to conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.084Z"
    }
   },
   "outputs": [],
   "source": [
    "#separating popular and unpopular songs to two dfs\n",
    "popular_songs_df = df_ohe[df_ohe['is_popular'] == 1]\n",
    "unpopular_songs_df = df_ohe[df_ohe['is_popular']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.088Z"
    }
   },
   "outputs": [],
   "source": [
    "#checking for genre occurence counts for popular songs\n",
    "popular_genre_df = popular_songs_df.iloc[:, 10:36].agg('sum').sort_values(ascending=False).reset_index()\n",
    "popular_genre_df.columns = ['genre', 'count']\n",
    "popular_genre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.092Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "sns.barplot(x=popular_genre_df['genre'].head(5), y=popular_genre_df['count'].head(5), \n",
    "           palette='dark:seagreen_r')\n",
    "\n",
    "ax=plt.gca()\n",
    "ax.set_xlabel('Genre')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Top 5 Most Frequent Genres Among Popular Songs')\n",
    "plt.tight_layout();\n",
    "plt.savefig('images/genre-popular.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above bar graph shows us the most frequent genres among popular songs. As we discussed above, most popular songs have Pop as their genre followed by Rap, Rock, Hip-Hop and Dance. These results make sense and are in-line with a survey conducted by IFPI (https://www.statista.com/chart/15763/most-popular-music-genres-worldwide/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.099Z"
    }
   },
   "outputs": [],
   "source": [
    "#checking for genre occurence counts for unpopular songs\n",
    "unpopular_genre_df = unpopular_songs_df.iloc[:, 10:36].agg('sum').sort_values(ascending=False).reset_index()\n",
    "unpopular_genre_df.columns = ['genre', 'count']\n",
    "unpopular_genre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.103Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "sns.barplot(x=unpopular_genre_df['genre'].head(5), y=unpopular_genre_df['count'].head(5), \n",
    "           palette='dark:#5A9_r')\n",
    "\n",
    "ax=plt.gca()\n",
    "ax.set_xlabel('Genre')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Top 5 Most Frequent Genres Among Unpopular Songs')\n",
    "plt.tight_layout();\n",
    "plt.savefig('images/genre-unpopular.jpg')\n",
    "# ax.set_xticklabels(ax.get_xticklabels(), rotation=45,ha='center');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most frequent genres of unpopular songs can be seen above. The results make sense as these genres tend to have a more niche fanbase or as in the case of \"Children's Music\" are listened to infrequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.108Z"
    }
   },
   "outputs": [],
   "source": [
    "#displaying percentages for each genre\n",
    "popular_genre_df['count']=popular_genre_df['count']/popular_genre_df['count'].sum()\n",
    "popular_genre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.112Z"
    }
   },
   "outputs": [],
   "source": [
    "#displaying percentages for each genre\n",
    "unpopular_genre_df['count']=unpopular_genre_df['count']/unpopular_genre_df['count'].sum()\n",
    "unpopular_genre_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.117Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#removing outliers from energy scores and separating them to Series for popular and unpopular songs\n",
    "popular_energy_clean = popular_songs_df[find_outliers_IQR(popular_songs_df['energy'])==False]\n",
    "print(popular_energy_clean['energy'].describe())\n",
    "\n",
    "unpopular_energy_clean = unpopular_songs_df[find_outliers_IQR(unpopular_songs_df['energy'])==False]\n",
    "print(unpopular_energy_clean['energy'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.121Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#storing mean energy scores in dict\n",
    "mean_energy = {'popular': popular_energy_clean['energy'].mean(), \n",
    "                     'unpopular': unpopular_energy_clean['energy'].mean()}\n",
    "#visualizing mean scores\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    ax.barh(y=list(mean_energy.keys()), \n",
    "            width=list(mean_energy.values()), \n",
    "            color=[sns.color_palette('viridis')[3],sns.color_palette('viridis')[4]]) \n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_xticks(np.arange(0,1.1,0.1))\n",
    "    ax.set_ylabel('Popularity of Songs')\n",
    "    ax.set_xlabel('Mean Energy Score')\n",
    "    ax.set_title('Mean Energy Scores for Popular and Unpopular Songs')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/energy.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T23:06:44.104480Z",
     "start_time": "2021-05-23T23:06:44.090504Z"
    }
   },
   "source": [
    "As we can see above, popular songs tended to be more energetic compared to unpopular songs. This makes sense since the most frequent genres we explored tend to also be energetic genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Danceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.126Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Median Danceability Scores')\n",
    "print('-------------------')\n",
    "print(f\"Unpopular Songs: {round(unpopular_songs_df['danceability'].median(),2)}\")\n",
    "print(f\"Popular Songs: {round(popular_songs_df['danceability'].median(),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.130Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.histplot(data = popular_songs_df, x='danceability', bins='auto')\n",
    "plt.vlines(x=popular_songs_df['danceability'].median(), ymin=0, ymax=1000, color='red', ls='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.135Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.histplot(data = unpopular_songs_df, x='danceability', bins='auto')\n",
    "plt.vlines(x=unpopular_songs_df['danceability'].median(), ymin=0, ymax=4000, color='red', ls='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.139Z"
    }
   },
   "outputs": [],
   "source": [
    "#removing outliers from danceability scores and separating them to Series for popular and unpopular songs\n",
    "popular_dance_clean = popular_songs_df[find_outliers_IQR(popular_songs_df['danceability'])==False]\n",
    "print(popular_dance_clean['danceability'].describe())\n",
    "\n",
    "unpopular_dance_clean = unpopular_songs_df[find_outliers_IQR(unpopular_songs_df['danceability'])==False]\n",
    "print(unpopular_dance_clean['danceability'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.142Z"
    }
   },
   "outputs": [],
   "source": [
    "#storing mean danceability scores in dict\n",
    "mean_danceability = {'popular': popular_dance_clean['danceability'].mean(), \n",
    "                     'unpopular': unpopular_dance_clean['danceability'].mean()}\n",
    "\n",
    "#visualizing mean scores\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    ax.barh(y=list(mean_danceability.keys()), \n",
    "            width=list(mean_danceability.values()), \n",
    "            color=[sns.color_palette('viridis')[0],sns.color_palette('viridis')[1]]) \n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_xticks(np.arange(0,1.1,0.1))\n",
    "    ax.set_ylabel('Popularity of Songs')\n",
    "    ax.set_xlabel('Mean Danceability Score')\n",
    "    ax.set_title('Mean Danceability Scores for Popular and Unpopular Songs')\n",
    "    plt.tight_layout();\n",
    "    plt.savefig('images/danceability.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, it is clear that the popular songs tended to have a higher danceability score compared to unpopular songs. This follows the same trend as the energy scores where majority of the popular songs are high energy and danceable (refer to Appendix A for definition of \"danceability\": high tempo, high beat strength etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acousticness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.149Z"
    }
   },
   "outputs": [],
   "source": [
    "#removing outliers from danceability scores and separating them to Series for popular and unpopular songs\n",
    "popular_acoustic_clean = popular_songs_df[find_outliers_IQR(popular_songs_df['acousticness'])==False]\n",
    "print(popular_acoustic_clean['acousticness'].describe())\n",
    "\n",
    "unpopular_acoustic_clean = unpopular_songs_df[find_outliers_IQR(unpopular_songs_df['acousticness'])==False]\n",
    "print(unpopular_acoustic_clean['acousticness'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.154Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.histplot(data = popular_acoustic_clean, x='acousticness', bins='auto')\n",
    "plt.vlines(x=popular_acoustic_clean['acousticness'].mean(), ymin=0, ymax=5000, color='red', ls='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.158Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(data = unpopular_songs_df, x='acousticness', bins='auto')\n",
    "plt.vlines(x=unpopular_songs_df['acousticness'].median(), ymin=0, ymax=30000, color='red', ls='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T15:46:51.162Z"
    }
   },
   "outputs": [],
   "source": [
    "#storing mean acousticness scores in dict\n",
    "mean_acousticness = {'popular': popular_acoustic_clean['acousticness'].mean(), \n",
    "                     'unpopular': unpopular_acoustic_clean['acousticness'].mean()}\n",
    "\n",
    "#visualizing mean scores\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    ax.barh(y=list(mean_acousticness.keys()), \n",
    "            width=list(mean_acousticness.values()), \n",
    "            color=[sns.color_palette('viridis')[2],sns.color_palette('viridis')[3]]) \n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_xticks(np.arange(0,1.1,0.1))\n",
    "    ax.set_ylabel('Popularity of Songs')\n",
    "    ax.set_xlabel('Mean Acousticness Score')\n",
    "    ax.set_title('Mean Acousticness Scores for Popular and Unpopular Songs')\n",
    "    plt.tight_layout();\n",
    "    plt.savefig('images/acousticness.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the energy and danceability scores we see that the popular songs tended to have a lower acousticness score. Since acoustic songs are usually lower energy and rarely danceable this follows the same trend we've been observing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSIONS & RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a competitive environment like the music streaming market, it is vital to retain current subscribers and add new subscribers over time. By accurately predicting which song will be popular next, companies like Spotify can leverage this information to create better playlists and find and sign exclusivity deals with established and up-and-coming artists more easily.  To sum up, our analysis of approximately 176,000 songs from 2019 showed the following:\n",
    "\n",
    "- Popular songs tend to have Pop, Rap, Rock, Hip-Hop and Dance as their genres.\n",
    "- More niche genres such as Children's Music, Comedy, Soundtracks, Classical and Jazz tend to be unpopular.\n",
    "- Generally, popular songs are higher energy, danceable, and therefore less acoustic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
